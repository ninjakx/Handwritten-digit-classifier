{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23100, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    " \n",
    "# load the MNIST digits dataset\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "# reshape the MNIST dataset from 784-dim vectors to 28 x 28 pixel images \n",
    "data = mnist.data.reshape((mnist.data.shape[0], 28, 28))\n",
    "\n",
    "# construct the training and testing splits and scale the data to the range [0, 1.0]\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data / 255.0, mnist.target.astype(\"int\"), test_size=0.33)\n",
    "\n",
    "trainData = trainData.reshape(trainData.shape[0], 28, 28)\n",
    "\n",
    "testData = testData.reshape(testData.shape[0], 28, 28)\n",
    "print(testData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "n_output = 10\n",
    "n_features = trainData.shape[1]\n",
    "n_hidden = 50\n",
    "l1 = 0.1\n",
    "l2 = 0.0\n",
    "epochs = 1000\n",
    "eta = 0.001\n",
    "alpha = 0.001\n",
    "decrease_const = 0.00001\n",
    "shuffle = True\n",
    "minibatches = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_weights():\n",
    "    \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "    w1 = np.random.uniform(-1.0, 1.0,size=n_hidden*(n_features + 1))\n",
    "    w1 = w1.reshape(n_hidden, n_features + 1)\n",
    "    w2 = np.random.uniform(-1.0, 1.0,size=n_output*(n_hidden + 1))\n",
    "    w2 = w2.reshape(n_output, n_hidden + 1)\n",
    "    return w1, w2\n",
    "\n",
    "def _sigmoid(z):\n",
    "    \"\"\"Compute logistic function (sigmoid)\n",
    "    Uses scipy.special.expit to avoid overflow\n",
    "    error for very small input values z.\n",
    "\n",
    "    \"\"\"\n",
    "    # return 1.0 / (1.0 + np.exp(-z))\n",
    "    return expit(z)\n",
    "\n",
    "def _sigmoid_gradient(z):\n",
    "    \"\"\"Compute gradient of the logistic function\"\"\"\n",
    "    sg = _sigmoid(z)\n",
    "    return sg * (1.0 - sg)\n",
    "\n",
    "def _add_bias_unit(X, how='column'):\n",
    "    \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "    if how == 'column':\n",
    "        X_new = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_new[:, 1:] = X\n",
    "    elif how == 'row':\n",
    "        X_new = np.ones((X.shape[0] + 1, X.shape[1]))\n",
    "        X_new[1:, :] = X\n",
    "    else:\n",
    "        raise AttributeError('`how` must be `column` or `row`')\n",
    "    return X_new\n",
    "\n",
    "def _feedforward(X, w1, w2):\n",
    "    a1 = _add_bias_unit(X, how='column')\n",
    "    z2 = w1.dot(a1.T)\n",
    "    a2 = _sigmoid(z2)\n",
    "    a2 = _add_bias_unit(a2, how='row')\n",
    "    z3 = w2.dot(a2)\n",
    "    a3 = _sigmoid(z3)\n",
    "    return a1, z2, a2, z3, a3\n",
    "\n",
    "def _L2_reg(lambda_, w1, w2):\n",
    "    \"\"\"Compute L2-regularization cost\"\"\"\n",
    "    return (lambda_/2.0) * (np.sum(w1[:, 1:] ** 2) + np.sum(w2[:, 1:] ** 2))\n",
    "\n",
    "def _L1_reg(lambda_, w1, w2):\n",
    "    \"\"\"Compute L1-regularization cost\"\"\"\n",
    "    return (lambda_/2.0) * (np.abs(w1[:, 1:]).sum() + np.abs(w2[:, 1:]).sum())\n",
    "\n",
    "def _get_cost(y_enc, output, w1, w2):\n",
    "    \"\"\"Compute cost function.\"\"\"\n",
    "    term1 = -y_enc * (np.log(output))\n",
    "    term2 = (1.0 - y_enc) * np.log(1.0 - output)\n",
    "    cost = np.sum(term1 - term2)\n",
    "    L1_term = _L1_reg(l1, w1, w2)\n",
    "    L2_term = _L2_reg(l2, w1, w2)\n",
    "    cost = cost + L1_term + L2_term\n",
    "    return cost\n",
    "\n",
    "def _get_gradient(a1, a2, a3, z2, y_enc, w1, w2):\n",
    "    \"\"\" Compute gradient step using backpropagation.\"\"\"\n",
    "    # backpropagation\n",
    "    sigma3 = a3 - y_enc\n",
    "    z2 = _add_bias_unit(z2, how='row')\n",
    "    sigma2 = w2.T.dot(sigma3) * _sigmoid_gradient(z2)\n",
    "    sigma2 = sigma2[1:, :]\n",
    "    grad1 = sigma2.dot(a1)\n",
    "    grad2 = sigma3.dot(a2.T)\n",
    "\n",
    "        # regularize\n",
    "    grad1[:, 1:] += l2 * w1[:, 1:]\n",
    "    grad1[:, 1:] += l1 * np.sign(w1[:, 1:])\n",
    "    grad2[:, 1:] += l2 * w2[:, 1:]\n",
    "    grad2[:, 1:] += l1 * np.sign(w2[:, 1:])\n",
    "\n",
    "    return grad1, grad2\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"Predict class labels\"\"\"\n",
    "    if len(X.shape) != 2:\n",
    "        raise AttributeError('X must be a [n_samples, n_features] array.\\n'\n",
    "                                 'Use X[:,None] for 1-feature classification,'\n",
    "                                 '\\nor X[[i]] for 1-sample classification')\n",
    "\n",
    "    a1, z2, a2, z3, a3 = _feedforward(X, w1, w2)\n",
    "    y_pred = np.argmax(z3, axis=0)\n",
    "    return y_pred\n",
    "\n",
    "def fit(X, y, print_progress=False):\n",
    "    \"\"\" Learn weights from training data.\"\"\"\n",
    "    w1, w2 = _initialize_weights()\n",
    "    cost_ = []\n",
    "    X_data, y_data = X.copy(), y.copy()\n",
    "    #y_enc = _encode_labels(y, n_output)\n",
    "\n",
    "    delta_w1_prev = np.zeros(w1.shape)\n",
    "    delta_w2_prev = np.zeros(w2.shape)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # adaptive learning rate\n",
    "        eta /= (1 + decrease_const*i)\n",
    "\n",
    "        if print_progress:\n",
    "            sys.stderr.write('\\rEpoch: %d/%d' % (i+1, epochs))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "        if shuffle:\n",
    "            idx = np.random.permutation(y_data.shape[0])\n",
    "            X_data, y_enc = X_data[idx], y_enc[:, idx]\n",
    "\n",
    "        mini = np.array_split(range(y_data.shape[0]), minibatches)\n",
    "        for idx in mini:\n",
    "\n",
    "            # feedforward\n",
    "            a1, z2, a2, z3, a3 = _feedforward(X_data[idx],\n",
    "                                                       w1,\n",
    "                                                       w2)\n",
    "            cost = _get_cost(y_enc=y_enc[:, idx],\n",
    "                                      output=a3,\n",
    "                                      w1=w1,\n",
    "                                      w2=w2)\n",
    "            cost_.append(cost)\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "            grad1, grad2 = _get_gradient(a1=a1, a2=a2,\n",
    "                                                  a3=a3, z2=z2,\n",
    "                                                  y_enc=y_enc[:, idx],\n",
    "                                                  w1=w1,\n",
    "                                                  w2=w2)\n",
    "\n",
    "            delta_w1, delta_w2 = eta * grad1, eta * grad2\n",
    "            w1 -= (delta_w1 + (alpha * delta_w1_prev))\n",
    "            w2 -= (delta_w2 + (alpha * delta_w2_prev))\n",
    "            delta_w1_prev, delta_w2_prev = delta_w1, delta_w2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'eta' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d18a0be85416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-dd2342a61a37>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(X, y, print_progress)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# adaptive learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0meta\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecrease_const\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'eta' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "# training\n",
    "fit(trainData, trainLabels, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
